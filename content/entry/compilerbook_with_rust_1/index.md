+++
title = "ğŸ“• Rustã§Rui Ueyamaå…ˆç”Ÿã®ä½ãƒ¬ã‚¤ãƒ¤ã‚’çŸ¥ã‚ŠãŸã„äººã®ãŸã‚ã®Cã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ä½œæˆå…¥é–€ã‚’ã‚„ã£ã¦ã¿ã‚‹1(ç’°å¢ƒæ§‹ç¯‰ã‹ã‚‰å››å‰‡æ¼”ç®—ã¾ã§)"
slug = "compilerbook_with_rust_1"
date = "2020-01-02"
draft = false
[taxonomies]
tags = ["book", "rust"]
+++

compilerbookã“ã¨[ä½ãƒ¬ã‚¤ãƒ¤ã‚’çŸ¥ã‚ŠãŸã„äººã®ãŸã‚ã®Cã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ä½œæˆå…¥é–€](https://www.sigbus.info/compilerbook)ã‚’Rustã§ã‚„ã£ã¦ã„ãã¾ã™ã€‚
æœ¬è¨˜äº‹ã§ã¯ã€ç’°å¢ƒæ§‹ç¯‰ã‹ã‚‰å››å‰‡æ¼”ç®—ã®testã‚’é€šã™ã¨ã“ã‚ã¾ã§ãŠã“ãªã„ã¾ã™ã€‚compilerbookã®ã‚¹ãƒ†ãƒƒãƒ—5: å››å‰‡æ¼”ç®—ã®ã§ãã‚‹è¨€èªã®ä½œæˆã¾ã§ã§ã™ã€‚

## æ¦‚è¦
æ¦‚è¦ã¨ã—ã¦ã¯ã€è¨ˆç®—ã®å¯¾è±¡ã¨ãªã‚‹æ–‡å­—åˆ—(`2*(3+4)`)ã‚’å¼•æ•°ã«ã¨ã‚‹CLIã‚’Rustã§ä½œæˆã—ã€ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’å‡ºåŠ›ã—ã¾ã™ã€‚ãã®ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’compilerbookãŒæä¾›ã—ã¦ãã ã•ã£ã¦ã„ã‚‹dockerä¸Šã®gccã§compileã—ã¦æ©Ÿæ¢°èªã‚’ç”Ÿæˆã™ã‚‹æµã‚Œã¨ãªã‚Šã¾ã™ã€‚
ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯è¨ˆç®—çµæœã‚’çµ‚äº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

```sh

# å…¥åŠ›ã‹ã‚‰ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’ç”Ÿæˆã™ã‚‹CLI
cargo run -- '2*(3+4)'
    Finished dev [unoptimized + debuginfo] target(s) in 0.01s
     Running `target/debug/r9cc '2*(3+4)'`
.intel_syntax noprefix
.global main
main:
  push 2
  push 3
  push 4
  pop rdi
  pop rax
  add rax, rdi
  push rax
  pop rdi
  pop rax
  imul rax, rdi
  push rax
  pop rax
  ret

# dockerä¸Šã§åˆ©ç”¨ã™ã‚‹ãŸã‚ã«cross compile
cross build --target x86_64-unknown-linux-musl

# buildæ¸ˆã®dockerä¸Šã§testã‚’å®Ÿè¡Œ
docker run -it -v $(pwd):/ws -w /ws compilerbook ./test.sh
```

compilerbookã«ãã£ã¦ã€(æ–‡å­—åˆ—->Tokenåˆ—)ã€(Tokenåˆ— -> AST)ã€(AST -> ã‚¢ã‚»ãƒ³ãƒ–ãƒª)ã®ï¼“ã¤ã®å¤‰æ›å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚
`main.rs`
```rust
use r9cc::{gen, parse, tokenize, Error};
use std::{env, io, process};

fn main() {
    let result = env::args()
        .skip(1)
        .next()
        .ok_or(Error::InputRequired)
        .and_then(|input| tokenize(&input))
        .and_then(|tokens| parse(tokens))
        .and_then(|ast| gen(&mut io::stdout(), &ast));

    if let Err(e) = result {
        match e {
            Error::Lexer(e) => {
                eprintln!("{}\n{}", env::args().skip(1).next().unwrap(), e);
            }
            _ => eprintln!("{}", e),
        }

        process::exit(1);
    }
}
```

## ç’°å¢ƒæ§‹ç¯‰

ç’°å¢ƒæ§‹ç¯‰ã¨ã„ã£ã¦ã‚‚ã€å¿…è¦ãªãƒ„ãƒ¼ãƒ«ãŒæƒã£ã¦ã„ã‚‹[Dockerfile](https://www.sigbus.info/compilerbook/Dockerfile)ã‚’æº–å‚™ã—ã¦ã„ãŸã ã„ã¦ã„ã‚‹ã®ã§ã€Rustå´ã ã‘ã§ã™ã€‚
compilerbookã§ã¯`9cc`ã¨ã„ã†åå‰ã§å®Ÿè£…ã—ã¦ã„ãã®ã§ã€`r9cc`ã¨ã—ã¾ã—ãŸã€‚[repositoryã¯ã“ã¡ã‚‰ã§ã™](https://github.com/ymgyt/r9cc)

```sh
# clone
git clone https://github.com/ymgyt/r9cc

# å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’install
cargo install cargo-make
cargo install cross

# version
rustc -V
rustc 1.40.0 (73528e339 2019-12-16)

cross -V 
cross 0.1.16
cargo 1.40.0 (bc8e4c8be 2019-11-22)

# docker imageã‚’build
cargo make image

# docker containerã¨interactiveã«ã‚„ã‚Šã¨ã‚Šã—ãŸã„å ´åˆ
# cargo make login

# r9ccã‚’build
cargo make build

# testã‚’å®Ÿè¡Œ
cargo make my_test
```




## tokenize

ç’°å¢ƒã‚‚ã¨ã¨ã®ã£ãŸã®ã§ã€å‡¦ç†ã®æµã‚Œã‚’ãŠã£ã¦ã„ãã¾ã™ã€‚ã¾ãšã¯ã€å…¥åŠ›æ–‡å­—åˆ—ã‚’tokenã®Vecã«å¤‰æ›ã™ã‚‹lexéƒ¨åˆ†ã‹ã‚‰ã§ã™ã€‚
ã“ã®éƒ¨åˆ†ã¯ã€[å®Ÿè·µRustå…¥é–€](https://www.amazon.co.jp/dp/B07QVQ7RDG)ã®ç¬¬9ç« ãƒ‘ãƒ¼ã‚µã‚’ä½œã‚‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚
https://github.com/ymgyt/r9cc/blob/7cad51b06d1ba4c1c73d5a01213128853bd115ff/src/lex/token.rs#L177

tokenã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã—ã¾ã—ãŸã€‚
```rust
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Loc(pub usize, pub usize);

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Annot<T> {
    pub value: T,
    pub loc: Loc,
}

impl<T> Annot<T> {
    fn new(value: T, loc: Loc) -> Self {
        Self { value, loc }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub enum TokenKind {
    Number(u64), // [0-9][0-9]*
    Plus,        // '+'
    Minus,       // '-'
    Asterisk,    // '*'
    Slash,       // '/'
    LParen,      // '('
    RParen,      // ')'
    Eof,         // sentinel
}

impl TokenKind {
    pub(crate) fn is_number(&self) -> bool {
        match *self {
            TokenKind::Number(_) => true,
            _ => false,
        }
    }
}

pub type Token = Annot<TokenKind>;
```
tokenã«ä½ç½®ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ã‚‚ãŸã›ã‚‹ãŸã‚ã«ã€`Annot`ã§wrapã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯å®Ÿè·µRustå…¥é–€ã§ãŠã“ãªã‚ã‚Œã¦ã„ãŸå®Ÿè£…æ–¹æ³•ã§ã€Genericsã®ä½¿ã„æ–¹ã¨ã—ã¦éå¸¸ã«å‚è€ƒã«ãªã‚Šã¾ã—ãŸã€‚
`Loc`ã®æƒ…å ±ã¯ã‚¨ãƒ©ãƒ¼æ™‚ã«ä»¥ä¸‹ã®ã‚ˆã†ãªè¡¨ç¤ºã‚’ã ã™ãŸã‚ã«åˆ©ç”¨ã—ã¾ã™ã€‚
```sh
./target/debug/r9cc '1 + 2 - aaa'  
1 + 2 - aaa
        ^ invalid char 'a'
```

tokenã®ç”Ÿæˆã¯`tokenize`é–¢æ•°ã§è¡Œã„ã¾ã™ã€‚
```rust
#[derive(Debug)]
struct Input<'a> {
    input: &'a [u8],
    pos: Cell<usize>,
}

impl<'a> Input<'a> {
    fn new(s: &'a str) -> Self {
        Self {
            input: s.as_bytes(),
            pos: Cell::new(0),
        }
    }
    fn consume_byte(&self, want: u8) -> Result<usize> {
        self.peek().and_then(|got: u8| {
            if got != want {
                let pos = self.pos();
                Err(Error::invalid_char(got as char, Loc(pos, pos + 1)))
            } else {
                Ok(self.pos_then_inc())
            }
        })
    }
    fn consume_numbers(&self) -> Result<(usize, u64)> {
        let start = self.pos();
        self.consume(|b| b"0123456789".contains(&b));
        let n = std::str::from_utf8(&self.input[start..self.pos()])
            .unwrap()
            .parse()
            .unwrap();
        Ok((start, n))
    }
    fn consume_spaces(&self) {
        self.consume(|b| b" \n\t".contains(&b))
    }
    fn consume(&self, mut f: impl FnMut(u8) -> bool) {
        while let Ok(b) = self.peek() {
            if f(b) {
                self.inc();
                continue;
            }
            break;
        }
    }
    fn peek(&self) -> Result<u8> {
        self.input
            .get(self.pos())
            .map(|&b| b)
            .ok_or_else(|| self.eof())
    }
    fn pos(&self) -> usize {
        self.pos.get()
    }
    fn inc(&self) {
        self.pos.set(self.pos() + 1);
    }
    fn pos_then_inc(&self) -> usize {
        let pos = self.pos();
        self.inc();
        pos
    }
    fn eof(&self) -> Error {
        let pos = self.pos();
        Error::eof(Loc(pos, pos))
    }
}

pub fn tokenize(input: &str) -> StdResult<Stream, crate::Error> {
    let mut tokens = Vec::new();
    let input = Input::new(input);

    macro_rules! push {
        ($lexer:expr) => {{
            let tk = $lexer?;
            tokens.push(tk);
        }};
    }
    loop {
        match input.peek() {
            Err(e) => match e.value {
                ErrorKind::Eof => {
                    tokens.push(Token::eof(Loc(input.pos(), input.pos())));
                    return Ok(tokens);
                }
                _ => return Err(e.into()),
            },
            Ok(b) => match b {
                b'0'..=b'9' => push!(lex_number(&input)),
                b'+' => push!(lex_plus(&input)),
                b'-' => push!(lex_minus(&input)),
                b'*' => push!(lex_asterisk(&input)),
                b'/' => push!(lex_slash(&input)),
                b'(' => push!(lex_lparen(&input)),
                b')' => push!(lex_rparen(&input)),
                _ if (b as char).is_ascii_whitespace() => input.consume_spaces(),
                _ => {
                    return Err(
                        Error::invalid_char(b as char, Loc(input.pos(), input.pos() + 1)).into(),
                    )
                }
            },
        }
    }
}

fn lex_number(input: &Input) -> Result<Token> {
    input
        .consume_numbers()
        .map(|(pos, n)| Token::number(n, Loc(pos, input.pos())))
}

fn lex_plus(input: &Input) -> Result<Token> {
    input
        .consume_byte(b'+')
        .map(|pos| Token::plus(Loc(pos, pos + 1)))
}

fn lex_minus(input: &Input) -> Result<Token> {
    input
        .consume_byte(b'-')
        .map(|pos| Token::minus(Loc(pos, pos + 1)))
}

fn lex_asterisk(input: &Input) -> Result<Token> {
    input
        .consume_byte(b'*')
        .map(|pos| Token::asterisk(Loc(pos, pos + 1)))
}

fn lex_slash(input: &Input) -> Result<Token> {
    input
        .consume_byte(b'/')
        .map(|pos| Token::slash(Loc(pos, pos + 1)))
}

fn lex_lparen(input: &Input) -> Result<Token> {
    input
        .consume_byte(b'(')
        .map(|pos| Token::lparen(Loc(pos, pos + 1)))
}

fn lex_rparen(input: &Input) -> Result<Token> {
    input
        .consume_byte(b')')
        .map(|pos| Token::rparen(Loc(pos, pos + 1)))
}
```

æ¼”ç®—å­ãªã‚‰ãã®ã¾ã¾tokenã«ã€ç©ºç™½ã¯ç„¡è¦–ã—ã¦ã€æ•°å­—ãªã‚‰é€”åˆ‡ã‚Œã‚‹ã¾ã§èª­ã‚“ã§ã‹ã‚‰å¤‰æ›ã‚’è©¦ã¿ã¾ã™ã€‚
å…¥åŠ›æ–‡å­—åˆ—ã¨ä½•byteã¾ã§èª­ã‚“ã ã‹ã‚’ä¸€ç·’ã«å¼•ãå›ã—ãŸã‹ã£ãŸã®ã§`Input`å‹ã§wrapã—ã¦ã„ã¾ã™ã€‚å…¥åŠ›æ–‡å­—åˆ—ã¯`&str`ã§å¯å¤‰å‚ç…§ãŒã¨ã‚Œãªã„ã®ã§ã€posã‚’`Cell`ã§wrapã—ã¦ã„ã¾ã™ã€‚
(ã“ã‚ŒãŒCellã®æ­£ã—ã„ä½¿ã„æ–¹ãªã®ã‹ã¯ã‚ã¾ã‚Šè‡ªä¿¡ãŒãªã„ã§ã™ã€‚)


## ASTã¸ã®å¤‰æ›

ç¶šã„ã¦ã€tokenåˆ—ã‚’Treeå‹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¤‰æ›ã—ã¾ã™ã€‚ASTã‚’è¡¨ã™Nodeã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã—ã¾ã—ãŸã€‚

```rust
#[derive(Debug, PartialEq)]
pub enum Kind {
    Add,
    Sub,
    Mul,
    Div,
    Number(u64),
}

pub type Link = Option<Box<Node>>;

#[derive(Debug, PartialEq)]
pub struct Node {
    pub kind: Kind,
    pub lhs: Link,
    pub rhs: Link,
}

impl Node {
    pub fn new(kind: Kind, lhs: Link, rhs: Link) -> Node {
        Self { kind, lhs, rhs }
    }
    pub fn link(node: Node) -> Link {
        Some(Box::new(node))
    }
    pub fn number(n: u64) -> Node {
        Node::new(Kind::Number(n), None, None)
    }
}
```

Cã®pointerã¯`Option<Box<T>>`ã§ä»£ç”¨ã—ã¾ã—ãŸã€‚(ã‚‚ã£ã¨ã„ã„æ–¹æ³•ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚)
ä»Šå›ã¯åˆ©ç”¨ã—ã¾ã›ã‚“ã§ã—ãŸãŒã€Rustã®pointerã®ã²ã¨ã¤ã§ã‚ã‚‹`Rc`ã«ã¤ã„ã¦ã¯@qnighyã•ã‚“ã®[ã“ã¡ã‚‰ã®è¨˜äº‹](https://qiita.com/qnighy/items/4bbbb20e71cf4ae527b9)ãŒå¤§å¤‰å‚è€ƒã«ãªã‚Šã¾ã—ãŸã€‚

å››å‰‡æ¼”ç®—ã‚’parseã™ã‚‹ãŸã‚ã®æ–‡æ³•è¦å‰‡ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
```
expr    = mul ("+" mul | "-" mul)*
mul     = primary ("*" primary | "/" primary)*
primary = num | "(" expr ")"
```

ã“ã®`expr`, `mul`, `primary`ãã‚Œãã‚Œã«å¯¾å¿œã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚

```rust
type Result<T> = StdResult<T, Error>;

pub fn parse(stream: Stream) -> StdResult<Node, crate::Error> {
    let mut tokens = stream.into_iter().peekable();
    expr(&mut tokens).map_err(|e| crate::Error::from(e))
}

fn expr<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<Node>
where
    Tokens: Iterator<Item = Token>,
{
    let mut node = mul(tokens)?;
    loop {
        if consume(tokens, TokenKind::Plus)? {
            node = Node::new(Kind::Add, Node::link(node), Node::link(mul(tokens)?));
        } else if consume(tokens, TokenKind::Minus)? {
            node = Node::new(Kind::Sub, Node::link(node), Node::link(mul(tokens)?));
        } else {
            return Ok(node);
        }
    }
}

fn mul<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<Node>
where
    Tokens: Iterator<Item = Token>,
{
    let mut node = primary(tokens)?;
    loop {
        if consume(tokens, TokenKind::Asterisk)? {
            node = Node::new(Kind::Mul, Node::link(node), Node::link(primary(tokens)?));
        } else if consume(tokens, TokenKind::Slash)? {
            node = Node::new(Kind::Div, Node::link(node), Node::link(primary(tokens)?));
        } else {
            return Ok(node);
        }
    }
}

fn primary<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<Node>
where
    Tokens: Iterator<Item = Token>,
{
    let node = if consume(tokens, TokenKind::LParen)? {
        let node = expr(tokens)?;
        expect(tokens, TokenKind::RParen)?;
        node
    } else {
        Node::number(expect_number(tokens)?)
    };
    Ok(node)
}

fn consume<Tokens>(tokens: &mut Peekable<Tokens>, kind: TokenKind) -> Result<bool>
where
    Tokens: Iterator<Item = Token>,
{
    let peek = tokens.peek();
    if peek.is_none() {
        return Ok(false);
    }
    let peek = peek.unwrap();
    if peek.is_kind(kind) {
        tokens.next();
        Ok(true)
    } else {
        Ok(false)
    }
}

fn expect<Tokens>(tokens: &mut Peekable<Tokens>, kind: TokenKind) -> Result<()>
where
    Tokens: Iterator<Item = Token>,
{
    let peek = tokens.peek();
    if peek.is_none() {
        return Err(Error::Eof);
    }
    let peek = peek.unwrap();
    if peek.is_kind(kind) {
        tokens.next();
        Ok(())
    } else {
        Err(Error::UnexpectedToken(peek.clone()))
    }
}

fn expect_number<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<u64>
where
    Tokens: Iterator<Item = Token>,
{
    let peek = tokens.peek();
    if peek.is_none() {
        return Err(Error::Eof);
    }
    let peek = peek.unwrap();
    match peek.value {
        TokenKind::Number(n) => {
            tokens.next();
            Ok(n)
        }
        _ => Err(Error::UnexpectedToken(peek.clone())),
    }
}
```

å„ªå…ˆåº¦ã®é«˜ã„æ¼”ç®—å­ã»ã©å…ˆã«å‡¦ç†ã•ã‚Œã¦ã€æœ¨ã®æ·±ã„ä½ç½®ã«ãŠã‹ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚(æ–‡æ³•è¦å‰‡ã‚’ãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«ã—ã¦å‹•ãã®ã¯æ„Ÿå‹•ã—ã¾ã™ã€‚)

## ã‚¢ã‚»ãƒ³ãƒ–ãƒªã®ç”Ÿæˆ

ASTã®parseå‡¦ç†ã«ã‚ˆã£ã¦ã€è¨ˆç®—ã®å„ªå…ˆåº¦ã¯æœ¨ã®æ·±ã•ã§è¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ä¸€ç•ªæ·±ã„ã¨ã“ã‚ã‹ã‚‰ã€æ¼”ç®—å­ã«å¯¾å¿œã™ã‚‹å‘½ä»¤ã‚’å®Ÿè¡Œã—ã¦è¨ˆç®—çµæœã‚’ã‚¹ã‚¿ãƒƒã‚¯ã«ä¿æŒã™ã‚‹ã‚ˆã†ãªã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

```rust
pub fn gen<W: Write>(w: &mut W, node: &Node) -> Result<(), crate::Error> {
    pre_gen(w)
        .and_then(|_| main_gen(w, node))
        .and_then(|_| post_gen(w))
        .map_err(|e| crate::Error::from(e))
}

fn pre_gen<W: Write>(w: &mut W) -> io::Result<()> {
    write!(
        w,
        ".intel_syntax noprefix\n\
         .global main\n\
         main:\n",
    )
}

fn main_gen<W: Write>(w: &mut W, node: &Node) -> io::Result<()> {
    if let NodeKind::Number(n) = node.kind {
        write!(w, "  push {}\n", n)?;
        return Ok(());
    }

    main_gen(w, &node.lhs.as_ref().unwrap())?;
    main_gen(w, &node.rhs.as_ref().unwrap())?;

    write!(w, "  pop rdi\n")?;
    write!(w, "  pop rax\n")?;

    match node.kind {
        NodeKind::Add => write!(w, "  add rax, rdi\n")?,
        NodeKind::Sub => write!(w, "  sub rax, rdi\n")?,
        NodeKind::Mul => write!(w, "  imul rax, rdi\n")?,
        NodeKind::Div => {
            write!(w, "  cqo\n")?;
            write!(w, "  idiv rdi\n")?;
        }
        _ => unreachable!(),
    }

    write!(w, "  push rax\n")?;

    Ok(())
}

fn post_gen<W: Write>(w: &mut W) -> io::Result<()> {
    write!(w, "{}{}", "  pop rax\n", "  ret\n")
}
```

(divã ã‘x86-64ã®ä»•æ§˜ãŒç‰¹æ®Šã§è¿½åŠ ã®å‡¦ç†ãŒå¿…è¦ã‚‰ã—ã„ã§ã™)
æ•°å€¤ãªã‚‰stackã«pushã—ã¦ã€æ¼”ç®—å­ãªã‚‰popã‚’2å›ãŠã“ãªã£ã¦ã‹ã‚‰è¨ˆç®—ã—ã¦çµæœã‚’stackã«æ›¸ãæˆ»ã™ã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†ã§ã™ã€‚


## test

ã“ã“ã¾ã§ã§ã€å…¥åŠ›æ–‡å­—åˆ—ã‹ã‚‰ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’å‡ºåŠ›ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
```sh
./target/debug/r9cc '6/2*(3+4)'   
.intel_syntax noprefix
.global main
main:
  push 6
  push 2
  pop rdi
  pop rax
  cqo
  idiv rdi
  push rax
  push 3
  push 4
  pop rdi
  pop rax
  add rax, rdi
  push rax
  pop rdi
  pop rax
  imul rax, rdi
  push rax
  pop rax
  ret
```

ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‹ã‚‰æ©Ÿæ¢°èªã¸ã®å¤‰æ›ã¯dockerä¸Šã§ãŠã“ãªã„ã€testã‚’èµ°ã‚‰ã›ã¾ã™ã€‚
testç”¨ã®scriptã¯compilerbookã®ã‚‚ã®ã‚’å®Ÿè¡Œpathã‚’ä¿®æ­£ã—ã¦åˆ©ç”¨ã—ã¾ã—ãŸã€‚
```bash
#!/bin/bash

CMD=./target/x86_64-unknown-linux-musl/debug/r9cc
TARGET=./target/tmp

mkdir -p "${TARGET}"

try() {
  expected="$1"
  input="$2"

  ${CMD} "$input" > "${TARGET}/tmp.s"
  gcc -o "${TARGET}/tmp" "${TARGET}/tmp.s"
  "${TARGET}/tmp"
  actual="$?"

  if [ "$actual" = "$expected" ]; then
    echo "$input => $actual"
  else
    echo "$input => $expected expected, but got $actual"
    exit 1
  fi
}

try 0 0
try 100 100
try 2 '1+1'
try 21 '3*(9-2)'
try 14 '(3+3)+2*(5-1)'

echo OK
```
dockerã®base imageã¯ubuntuãªã®ã§ã€crossã‚’åˆ©ç”¨ã—ã¦cross compileã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰ã€dockerä¸Šã§ä¸Šè¨˜ã®test.shã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```sh
[loc rs/r9cc] cargo make build 
[cargo-make] INFO - cargo make 0.25.0
[cargo-make] INFO - Project: r9cc
[cargo-make] INFO - Build File: Makefile.toml
[cargo-make] INFO - Task: build
[cargo-make] INFO - Profile: development
[cargo-make] INFO - Running Task: init
[cargo-make] INFO - Running Task: build
[cargo-make] INFO - Execute Command: "cross" "build" "--target" "x86_64-unknown-linux-musl"
   Compiling r9cc v0.1.0 (/project)
    Finished dev [unoptimized + debuginfo] target(s) in 11.71s
[cargo-make] INFO - Running Task: end
[cargo-make] INFO - Build Done in 13 seconds.
[loc rs/r9cc] cargo make my_test   
[cargo-make] INFO - cargo make 0.25.0
[cargo-make] INFO - Project: r9cc
[cargo-make] INFO - Build File: Makefile.toml
[cargo-make] INFO - Task: my_test
[cargo-make] INFO - Profile: development
[cargo-make] INFO - Running Task: init
[cargo-make] INFO - Running Task: my_test
0 => 0
100 => 100
1+1 => 2
3*(9-2) => 21
(3+3)+2*(5-1) => 14
OK
[cargo-make] INFO - Running Task: end
[cargo-make] INFO - Build Done in 2 seconds.
```

## ã¾ã¨ã‚

ç’°å¢ƒæ§‹ç¯‰ã‹ã‚‰å››å‰‡æ¼”ç®—ã¾ã§ã‚’è¡Œã„ã¾ã—ãŸã€‚æ¬¡å›ã¯ã‚¹ãƒ†ãƒƒãƒ—6 å˜é …ãƒ—ãƒ©ã‚¹ã¨å˜é …ãƒã‚¤ãƒŠã‚¹ã‹ã‚‰ã‚’äºˆå®šã—ã¦ã„ã¾ã™ã€‚
ã“ã®ã‚ˆã†ãªã™ã°ã‚‰ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç„¡æ–™ã§å…¬é–‹ã—ã¦ãã ã•ã£ã¦ã„ã‚‹Rui Ueyamaå…ˆç”Ÿã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚(ãªã‚“ã‚‰ã‹ã®å½¢ã§è²©å£²ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã—ãŸã‚‰å¿…ãšè³¼å…¥ã—ã¾ã™)


## å‚è€ƒ

- compilerbook ä½ãƒ¬ã‚¤ãƒ¤ã‚’çŸ¥ã‚ŠãŸã„äººã®ãŸã‚ã®Cã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ä½œæˆå…¥é–€
  - Rui Ueyama
  - https://www.sigbus.info/compilerbook
- å®Ÿè·µRustå…¥é–€
  - Îºeen , æ²³é‡ é”ä¹Ÿ , å°æ¾ ç¤¼äºº
  - https://www.amazon.co.jp/dp/B07QVQ7RDG

