+++
title = "📕 プログラマーのためのCPU入門を読んだ感想"
slug = "what-a-programmer-should-know-about-the-cpu"
description = "プログラマーのためのCPU入門の素晴らしさを語ります"
date = "2023-03-12"
draft = true
[taxonomies]
tags = ["book"]
[extra]
image = "images/emoji/closed_book.png"
+++

## Memo

* 2章: 命令流の密度を高めたい。(命令の完了を待たずに次の命令を実行したい)

## 読んだ本


{{ figure(images=["images/what-a-programmer-should-know-about-the-cpu-book.png"], href="https://www.lambdanote.com/products/cpu") }}

[プログラマーのためのCPU入門](https://www.lambdanote.com/products/cpu)  
著者: Takenobu Tani

会社で読まれた方がオススメされており、読んでみたので感想を書きます。  
出版社は[ラムダノート](https://www.lambdanote.com/)です。  
基本的には、わかりやすい、ありがたい、助かったしか言っていないのですが、もう少し具体的に述べます。


## まとめ

非常に良かったです。この本を出版してくれてありがとうございますという感謝の気持ちでいっぱいです。  
具体的には以下の点がよかったです。

* CPUの速度向上の為には命令流の密度を上げる必要がある -> そのための工夫 -> それにより発生する問題 -> 問題へのアプローチという章展開が非常にわかりやすい
* 新しい概念(パイプライン、スーパースカラ、アウトオブオーダー, 分岐命令)が登場する際に必ず図による説明がある
* 同じ概念がVendorや本(パタヘネ)では異なる用語で説明されている場合にその揺らぎを補足してくれる
* Assembly 

プログラムはメモリから命令を取得して順番に実行していく、くらいのメンタルモデルだと解像度が一段上がると思いました。


## 第1章 CPUは如何にしてソフトウェアを高速に実行するのか

### CPUの性能とは

本書はCPUを性能の面から眺めるのですが、そもそも性能とはというところから始めてくれます。  

$$ CPU時間 = \frac{実行命令数}{プログラム} \times \frac{クロックサイクル数}{実行命令数} \times \frac{秒数}{クロックサイクル数} $$

そして、CPUの性能とは、上記で定めるCPU時間が短いほどよいとします。

$$ CPU時間 = \frac{秒数}{プログラム} $$

のようにせず、わざわざ3項にしているかというと、各項がそれぞれ、CPUの異なる側面を表すからです。  
具体的には、第1項がプログラムを構成する命令数、コンパイラ、命令セットアーキテクチャによって決まります。  
第2項はCPUの内部構造(microarchitecture)、第3項は半導体や回路実装技術がそれぞれ対応します。

### 命令流

プログラムをbuild/compileして機械語にしてCPUに渡しますが、CPUからこの機械語がどう見えているかというと、ある種の命令流として見えていると説明されます。  
そして本書ではこの命令流を早くするためにCPUが行っている工夫と、遅くなる要因という観点から章が構成されます。


## 第2章 命令の密度を上げるさまざまな工夫

CPUの命令流を速くするためにその密度に着目します。密度というのは、実行中のCPUのスナップショットを採ったときにどれくらいの命令が実行中かという概念と理解しています。  

まず逐次処理から始めます。  


{{ figure(images=["images/pipe_1.svg"], caption="逐次処理") }}

これはある命令の実行を完了してから次の命令の実行を開始する処理方法です。実行中のCPUのどの時点でも1つの命令しか実行していないので密度としては最も低い状態です。  
さらに、命令実行の各処理(ステージ)を考慮すると逐次処理は以下のように表すことができます。

{{ figure(images=["images/pipe_2.svg"], caption="ステージaware") }}

次にパイプライン化します。今までは前の命令の実行完了まで待ってから次の命令を実行していましたが、完了まで待つのではなく、ステージの完了まで待ってから次の命令を実行します。  
この結果、ある1時点をみるとステージ数の命令が実行中となります。  

{{ figure(images=["images/pipe_3.svg"], caption="パイプライン化") }}

なお、パイプライン化により、前の命令の実行の完了を待たずに次の命令を実行することになります。これは広い意味での「投機的な処理」を導入するものと説明されます。このことが次章以降のデータ依存関係や、分岐命令の話につながります。  

そして、このパイプラインを物理的に複数設けるアプローチがスーパースカラ化です。  

{{ figure(images=["images/pipe_4.svg"], caption="スーパースカラ化") }}

最後に、ステージ分割を更に推し進め(スーパーパイプライン化)し、スーパースカラの並列度を4に、ステージ分割数を12にすると現代の標準的なCPUと同程度の規模感になるそうです。  

{{ figure(images=["images/pipe_5.svg"], caption="4並列、12段ステージ") }}

最初の逐次処理と比較すると密度が向上していることがわかります。  
スーパースカラやパイプライン化は概念としては知っていましたが命令流の密度という観点から整理してくれている本章の説明はとてもわかりやすかったです。


## 第3章 データ依存関係

第2章で導入されたパイプライン化により命令流の密度を高めることができました。ただし、パイプライン化によって、先の命令の実行完了を待たずに次の命令の実行が開始されます。  
これによって命令間に依存関係がある場合に問題が生じます。具体的には  

```
add x1, x2, x3
sub x4, x5, x1
```

のように`add`命令で更新したregisterを後続の`sub`命令で利用する場合、`add`命令の完了によってx1 registerが更新されてからでないと`sub`命令が実行できません。  
この命令を待機している間はパイプラインのステージの一部が利用されていない状態となってしまい、命令流の密度が低下してしまいます。  
そこで、依存関係によって待機している命令を実行する代わりに別の命令を先に実行することで、ステージの空きを埋めるアウトオブオーダーという手法が導入されます。  
また、データの依存関係にもいろいろ種類があり、依存関係の種類によっては、registerのリネームで対応できるといった説明もあります。  

アウトオブオーダーの存在自体は、[Atomics and Locksを読んで](https://blog.ymgyt.io/entry/rust_atomics_and_locks/)知っていたのですがどういう理由でそれが実行されるかはわかっていなかったので本章の説明はとてもわかりやすかったです。  

### 命令レイテンシの計測実験

TODO


## 第4章 分岐命令

アウトオブオーダーをもってしてもカバーできない命令流の密度低下要因に分岐命令があります。  
というのも、ifのような命令は実行して条件成立を判断したのちに、pc registerを更新することで命令流を切り替えるので分岐命令の後の命令の実行が全て無駄になる可能性があります。  

そこで、これに対処するために分岐予測という仕組みがCPUに実装されます。  
分岐予測では、分岐命令が実行されるたびにその命令のアドレスと分岐先を専用の記憶領域(BTB)に保持しておき、命令をfetchする度にアドレスで検索して分岐命令かを判定します。さらに分岐命令の条件の成否の履歴を保持しておき、分岐予測に役立てるそうです。 ifを実行する度にCPUではこんなことが起きているとしり結構衝撃的でした。  
本章に限ったことではないですが、参考として米国特許までもが挙げられており筆者の知識の深さに驚かされます。

### TODO 予測ミス率の計測


## 第5章 キャッシュメモリ

CPUからメモリへのアクセスには10 ~ 100サイクル程度を要する。そしてアウトオブオーダー実行で埋められるサイクル数にも限界がある。そこで、CPU、メモリ間にキャッシュが導入されます。  
メモリへの書き込みはキャッシュになされるのでキャッシュとメモリ間の不整合が発生することとなるがこの問題は10章で扱います。  

キャッシュを導入したとしてもキャッシュミス自体は避けられず、その影響は大きい。  
そこでキャッシュミスが起きやすい場合を3つに類型化し、それぞれ対策していきます。  
まず初期参照ミスに対してはキャッシュラインで、容量性ミスに対しては階層化、競合性ミスにはセットアソシアティブ方式で対処します。  
キャッシュの話でキャッシュラインや階層化がよく説明されますが、それをキャッシュミスの類型と対応させる説明がわかりやすかったです。  
また、自分はフルアソシアティブ方式とセットアソシアティブ方式の違いやway数というものがよくわかっていなかったので本章説明は非常にありがたかったです。  
普段のアプリケーションでキャッシュラインを意識することはほとんどないのですが、ライブラリのコードを見ているとキャッシュラインを意識したコメントを時々見かけることもあります。現状ではstructを64byte以内にしておくとキャッシュに乗りやすいくらいの理解度です。

### TODO キャッシュミスの測定


## 第6章 仮想記憶

Virtual addressとphysical addressの変換を行うレイヤーが仮想記憶。  仮想記憶を導入することで様々なメリットがある一方で、対応関係の情報自体(ページテーブル)はメモリ上にある。したがって、メモリにアクセスする際には対応関係の解決のためにメモリアクセスが必要になるので都合2回のアクセスが必要となってしまう。  
これではキャッシュが解決しようとした問題と同じことが起きてしまう。そこで、ページテーブルの一部をCPU上に保持すること(TLB)でアドレス解決時のメモリアクセスを抑えるようにする。  

自分はページテーブルとTLBの関係の理解が曖昧だったので、本章の説明もとてもありがたかったです。  
また、プロセスよりもスレッドの方が切り替えコストが低い理由としてTLBのキャッシュミスが影響しているのもなるほどでした。  
加えてページテーブルを大きくしたい動機がわかっていなかったので、TLBのキャッシュミスを下げられるという説明もとてもわかりやすかったです。  

CPUの命令流の密度を高めるための工夫を知ると、ページフォルト時にI/Oが発生したらもう今までの苦労が全部水の泡になるというのが腹落ちできたのもうれしいです。

### TODO TLBミス計測

## 第7章 I/O

CPUの命令実行によりCPUから外部のデバイスにアクセスする仕組みについて。  
自分は、メモリマップドI/Oと専用のI/O命令によるアクセスの方式をごっちゃになって理解していたので、本章の整理は非常に助かりました。  
また、DMAコントローラとCPUの関係の説明もわかりやすかったです。

### TODO 検証


## 第8章 システムコール、例外、割り込み

分岐命令以外で、命令流の切り替えが起きるケースについて。  
exception, interrupt, trap, fault, system call,...等を命令流の特別な切り替えという観点から整理してくれています。  
本書はCPUに関連するトピックを命令流という観点から整理してくれておりますが、本章の整理は特にわかりやすいです。  
定義の仕方にもよりますが、システムコール、例外、割り込みについてメンタルモデルを確立したいと思う方は本章とてもおすすめしたいです。  

またこれまでの章で、割り込みコントローラー, アドレス変換処理、キャッシュ、I/Oバス等にふれましたが、それら関連コンポーネントと各種事象がどう対応しているかの図が非常にわかりやすかったです。  
加えて、システムコール、例外、割り込み時の挙動の説明も具体的で、ベクターテーブルの説明もあります。  
システムコールは遅いと漠然と思っていたのですが、なぜ遅いかが、これまでのパイプラインやキャッシュの観点から理解できます。章だてが練られていると思わされます。

### TODO検証


## 第9章 マルチプロセッサ

2つ以上のCPUによって構成される場合について。  
マルチプロセッサとマルチコアの文脈による使い分けの説明がなるほどでした。  
自分はマルチコアと言った際に想定されるハードウェア構成は一つだと思っていたのですが、多様な構成が可能なのが勉強になりました。  
特に、メッセージ交換型でメモリ共有がなされていない場合があるとは思ってもみなかったです。

## 第10章 キャッシュコヒーレンス制御

前章で説明された共有メモリ型における問題点と対処法について。  
具体的には、CPUごとにcacheを保持することとなるので、同一メモリアドレスのコピーが複数存在するため、他のCPUの更新結果が別のCPUから読めないといったキャッシュ間の整合性が崩れる問題に対処する必要がある。  
キャッシュコヒーレンスの問題状況を丁寧に説明してくれるので、MSIプロトコルの立ち位置が理解しやすかったです。  
最初にキャッシュコヒーレンスの話を知った際は、変数に書き込むと裏ではCPU間で当該キャッシュを無効にするやり取りが行われているなんて思いもしませんでした。  
MSIプロトコルについての説明もあります。

### TODO 検証



## 第11章 メモリ順序付け

1つのCPUから複数のメモリアクセスに何らかの順序関係を強制する手段としてのmemory orderingについて。  
なぜメモリアクセスが一つのCPU内で入れ替わるのかの説明が参考になります。  
fench命令の必要性や、acquire, release命令の動作が具体例つきでわかりやすいです。  
また、本章で説明されるメモリ順序付けは1つのCPUからのメモリアクセスについてである点が強調されています。そのため、本章とRust Atomics and Locksを併せて読むのがオススメです。  
fenceやldar, stlr命令があくまで1CPUに対する制約であり、happens-before relationshipとは別の話と整理できて非常に理解が進みました。 

## 第12章 不可分操作

本章では共通のメモリを2つ以上のCPU間で相互に更新する場合についてです。  
メモリオーダリングに比べて、不可分操作の話は解決したい問題がわかりやすく、解決法も専用の命令使うという話で意外とわかりやすい印象があります。  
swapやcompare and swap命令がどのように動作するのかの説明があります。このあたりはプログラム言語でもそのままapiになっている気がするので、内部動作を知るのが結局近道だと思いました。  

### TODO 検証


## 第13章 高速なソフトウェアを書く際には何に注目すべきか

これまでのまとめ。  
高速なソフトウェアを書くうえで、何に着目するかは、実行対象のソフトウェアだけでなくプログラミング言語、OS、CPU等にも依存するため難しい問題。  
そんな中、大枠としてどのようにアプローチできるかについて教えてくれます。

## 付録A CPUについてさらに広く深く知るには

CPUについてさらに詳しく知りたい人に向けた情報源の紹介。  
書籍だけでなく、論文や特許、講義資料も載っておりすごいです。
自分は、Systems Performance Second Edition(詳解システム・パフォーマンス 第2版)を読んでみようと思っております。  
あとがきにも著者のオススメがのっているので要チェックです。

## 付録B 各CPUの基本的な命令

x86, Arm, RISC-Vそれぞれの基本的な命令を解説してくれます。  
自分のアセンブリの学習ソースが基本的に本のappendixなのでこういう非常にありがたいです。  
RISC-Vは比較命令で暗黙的なレジスタを更新しないという学びもありました。


## 付録C 現代的なCPUの実装例 (BOOM)

[BOOM](https://boom-core.org/)というRISC-Vの実装について。  
まったく読めてないです。  
Chiselで書かれているらしいです。いつもハードウェア記述言語の文脈で突然Scalaでてきて驚きます。

## 付録D マイクロオペレーション方式と、その命令レイテンシ

x86のようなCISCで出てくるマイクロオペレーションについて。  
今まで、アセンブリってCPUが実際に実行している機械語と1:1対応していると思っていたのですが、もはやアセンブリでさえ抽象化されたレイヤーなのかと思ってしまいます。


## 付録E GPUおよびベクトル方式におけるパイプラインの高密度化の工夫

本章で扱えなかったGPUについて。  
自分はCPUとGPUって具体的にどう連携しているのかが知りたいです。  
7章によるとCPUからはI/OデバイスとしてGPUが見えているはずなので、I/O処理としてGPUに処理を依頼する感じになるのでしょうか。  
でもそうなるとプログラミング言語からどうやって扱うのだろうか。

## 付録F CPUの性能向上の物理的な難しさ

CPUの物理的な側面について。  
物理も学びたいです...


